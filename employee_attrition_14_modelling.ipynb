{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 14: Rylie Ramos-Marquez, Derek Atabayev, Vishnu Garigipati\n",
    "\n",
    "Are employees likely to resign?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both available and competition datasets as pd.DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "with open(\"attrition_available_14.pkl\", \"rb\") as f:\n",
    "    available_data = pd.read_pickle(f)\n",
    "\n",
    "with open(\"attrition_compet_14.pkl\", \"rb\") as f:\n",
    "    competition_data = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Exploratory EDA\n",
    "\n",
    "Maniupating the dataframe available_data to gain insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1426 entries, 0 to 1425\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   hrs                      1426 non-null   float64\n",
      " 1   absences                 1426 non-null   int64  \n",
      " 2   JobInvolvement           1279 non-null   float64\n",
      " 3   PerformanceRating        1278 non-null   float64\n",
      " 4   EnvironmentSatisfaction  1419 non-null   float64\n",
      " 5   JobSatisfaction          1420 non-null   float64\n",
      " 6   WorkLifeBalance          1414 non-null   float64\n",
      " 7   Age                      1426 non-null   int64  \n",
      " 8   Attrition                1426 non-null   object \n",
      " 9   BusinessTravel           1426 non-null   object \n",
      " 10  Department               1426 non-null   object \n",
      " 11  DistanceFromHome         1426 non-null   int64  \n",
      " 12  Education                1426 non-null   int64  \n",
      " 13  EducationField           1426 non-null   object \n",
      " 14  EmployeeCount            1426 non-null   int64  \n",
      " 15  EmployeeID               1281 non-null   float64\n",
      " 16  Gender                   1426 non-null   object \n",
      " 17  JobLevel                 1426 non-null   int64  \n",
      " 18  JobRole                  1292 non-null   object \n",
      " 19  MaritalStatus            1426 non-null   object \n",
      " 20  MonthlyIncome            1426 non-null   int64  \n",
      " 21  NumCompaniesWorked       1421 non-null   float64\n",
      " 22  Over18                   1426 non-null   object \n",
      " 23  PercentSalaryHike        1426 non-null   int64  \n",
      " 24  StandardHours            1426 non-null   int64  \n",
      " 25  StockOptionLevel         1426 non-null   int64  \n",
      " 26  TotalWorkingYears        1422 non-null   float64\n",
      " 27  TrainingTimesLastYear    1426 non-null   int64  \n",
      " 28  YearsAtCompany           1426 non-null   int64  \n",
      " 29  YearsSinceLastPromotion  1426 non-null   int64  \n",
      " 30  YearsWithCurrManager     1426 non-null   int64  \n",
      "dtypes: float64(9), int64(14), object(8)\n",
      "memory usage: 345.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "available_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(available_data.info()) # inspect column types and counts\n",
    "# we can see that this dataset is about 1426 unique employees (1281 of them have ID) and various fields relating to their employment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1426, 31)\n"
     ]
    }
   ],
   "source": [
    "# find the number of features and instances\n",
    "\n",
    "print(available_data.shape)\n",
    "# shape returns a tupe of (instances, features) which is (1426, 35)\n",
    "# however from above we can see there are missing values for EmployeeID in 1426 - 1281 = 145 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrs                        float64\n",
      "absences                     int64\n",
      "JobInvolvement             float64\n",
      "PerformanceRating          float64\n",
      "EnvironmentSatisfaction    float64\n",
      "JobSatisfaction            float64\n",
      "WorkLifeBalance            float64\n",
      "Age                          int64\n",
      "Attrition                   object\n",
      "BusinessTravel              object\n",
      "Department                  object\n",
      "DistanceFromHome             int64\n",
      "Education                    int64\n",
      "EducationField              object\n",
      "EmployeeCount                int64\n",
      "EmployeeID                 float64\n",
      "Gender                      object\n",
      "JobLevel                     int64\n",
      "JobRole                     object\n",
      "MaritalStatus               object\n",
      "MonthlyIncome                int64\n",
      "NumCompaniesWorked         float64\n",
      "Over18                      object\n",
      "PercentSalaryHike            int64\n",
      "StandardHours                int64\n",
      "StockOptionLevel             int64\n",
      "TotalWorkingYears          float64\n",
      "TrainingTimesLastYear        int64\n",
      "YearsAtCompany               int64\n",
      "YearsSinceLastPromotion      int64\n",
      "YearsWithCurrManager         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check which variables are categorical / numerical\n",
    "\n",
    "print(available_data.dtypes)\n",
    "# we can see that the majority of the columns are numerical, with the exception of the following:\n",
    "# Attrition, BusinessTravel, Department, Education, Gender, Job Role, MaritalStatus, Over18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EducationField is high cardinality\n",
      "JobRole is high cardinality\n",
      "Values for EducationField:  ['Life Sciences' 'Medical' 'Human Resources' 'Marketing'\n",
      " 'Technical Degree' 'Other']\n",
      "Values for JobRole Field:  ['Research Scientist' 'Sales Executive' 'Manager' 'Laboratory Technician'\n",
      " 'Manufacturing Director' 'Healthcare Representative'\n",
      " 'Sales Representative' 'Research Director' nan 'Human Resources']\n"
     ]
    }
   ],
   "source": [
    "# from the categorical variables: Attrition, BusinessTravel, Department, EducationField, Gender, Job Role, MaritalStatus, Over18, check which have high cardinality\n",
    "\n",
    "list_of_categorical = ['Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18']\n",
    "\n",
    "# print cardinality for each\n",
    "for col in list_of_categorical:\n",
    "    if available_data[col].nunique() > 5: # check if cardinalty > 5, then this is considered high cardinality\n",
    "        print(col, \"is high cardinality\")\n",
    "\n",
    "# observe that EducationField and JobRole are high cardinality\n",
    "\n",
    "print(\"Values for EducationField: \", available_data['EducationField'].unique()) # spans an all-encompassing range of education fields\n",
    "print(\"Values for JobRole Field: \" , available_data['JobRole'].unique()) # contains 9 unique job roles as possible fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobInvolvement             147\n",
      "PerformanceRating          148\n",
      "EnvironmentSatisfaction      7\n",
      "JobSatisfaction              6\n",
      "WorkLifeBalance             12\n",
      "EmployeeID                 145\n",
      "JobRole                    134\n",
      "NumCompaniesWorked           5\n",
      "TotalWorkingYears            4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check columns that have missing values\n",
    "\n",
    "print(available_data.isnull().sum()[available_data.isnull().sum() > 0])\n",
    "# filter by columns that have missing values\n",
    "\n",
    "# 9 features have missing values, with the most missing in JobInvolvement, PerformanceRating, EmployeeID, JobRole\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant Columns:  Index(['EmployeeCount', 'Over18', 'StandardHours'], dtype='object')\n",
      "['Y']\n",
      "[8]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Check whether there are constant columns\n",
    "\n",
    "print(\"Constant Columns: \", available_data.columns[available_data.nunique() == 1]) # if the number of unique values in a column is 1, then it is a constant column\n",
    "\n",
    "# there are three constant columns in the dataset: Over18, StandardHours, EmployeeCount\n",
    "\n",
    "print(available_data['Over18'].unique()) # only one unique value\n",
    "print(available_data['StandardHours'].unique())\n",
    "print(available_data['EmployeeCount'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the columns suggests all employees are Over18, all work standard hours, and there is only one employee count per row\n",
    "# delete these constant columns\n",
    "available_data.drop(columns=['Over18', 'StandardHours', 'EmployeeCount'], inplace=True)\n",
    "competition_data.drop(columns=['Over18', 'StandardHours', 'EmployeeCount'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attrition\n",
      "No     715\n",
      "Yes    711\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Attrition is the target variable in this problem\n",
    "\n",
    "print(available_data['Attrition'].value_counts())\n",
    "\n",
    "# so this is a binary classification problem\n",
    "\n",
    "# balanced dataset, with 715 employees who have not left the company and 711 employees who have left the company\n",
    "# this means every row has a target value, so we do not need to drop any rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Basic Methods (Trees, KNN, and Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General decisions:\n",
    "\n",
    "1. Split 70% train, 30% test, because the dataset is small, and we need a large enough test size to help detect overfitting\n",
    "\n",
    "2. Will return also a classification report: precision, recall, f1-score, and support, because this gives a more comprehensive view\n",
    " - Precision is especially valuable because it essentially checks how reliable our predictions (in the positive case are)\n",
    " - Support prevents any random imbalances that could have occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define feature matrix X and target vector y\n",
    "X = available_data.drop(columns=['Attrition'])\n",
    "y = available_data['Attrition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100545358)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method One (default hyperparamaters): Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  0.02600550651550293\n",
      "Accuracy:  0.8636363636363636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       142\n",
      "           1       0.83      0.91      0.87       144\n",
      "\n",
      "    accuracy                           0.86       286\n",
      "   macro avg       0.87      0.86      0.86       286\n",
      "weighted avg       0.87      0.86      0.86       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Use a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define the preprocessor\n",
    "# scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')), # impute missing values with the mean\n",
    "            ('scaler', MinMaxScaler()) # scale the numerical features\n",
    "        ]), X.select_dtypes(include=['int64', 'float64']).columns)\n",
    "    ])\n",
    "# the preprocessor will impute missing values with the mean and scale the numerical features\n",
    "\n",
    "# Define the model\n",
    "\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', DecisionTreeClassifier(random_state=100545358))])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train_encoded)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: \", end - start)\n",
    "\n",
    "# Predict the target values\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Also return a classification report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n",
    "# this returns a classification report with precision, recall, f1-score, and support for each class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method Two (default hyperparameters): KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  0.012004613876342773\n",
      "Accuracy:  0.7307692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       142\n",
      "           1       0.73      0.74      0.73       144\n",
      "\n",
      "    accuracy                           0.73       286\n",
      "   macro avg       0.73      0.73      0.73       286\n",
      "weighted avg       0.73      0.73      0.73       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train_encoded)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: \", end - start)\n",
    "\n",
    "# Predict the target values\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "print (classification_report(y_test_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method Three (default hyperparameters): Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  0.021003246307373047\n",
      "Accuracy:  0.6783216783216783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       142\n",
      "           1       0.67      0.71      0.69       144\n",
      "\n",
      "    accuracy                           0.68       286\n",
      "   macro avg       0.68      0.68      0.68       286\n",
      "weighted avg       0.68      0.68      0.68       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', LogisticRegression(random_state=100545358))])\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train_encoded)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: \", end - start)\n",
    "\n",
    "# Predict the target values\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "print(classification_report(y_test_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order of performance:\n",
    "\n",
    "Decision Trees performs best, followed by Logistic Regression and KNN\n",
    "\n",
    "Part 3: We can check if it is justifiable to switch to an 80/20 split so that KNN and Logistic Regression might be able to perform better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with 0.2 testing split\n",
      "Training time:  0.026006698608398438\n",
      "Accuracy:  0.6783216783216783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       142\n",
      "           1       0.67      0.71      0.69       144\n",
      "\n",
      "    accuracy                           0.68       286\n",
      "   macro avg       0.68      0.68      0.68       286\n",
      "weighted avg       0.68      0.68      0.68       286\n",
      "\n",
      "KNN with 0.2 testing split\n",
      "Training time:  0.013001680374145508\n",
      "Accuracy:  0.7307692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       142\n",
      "           1       0.73      0.74      0.73       144\n",
      "\n",
      "    accuracy                           0.73       286\n",
      "   macro avg       0.73      0.73      0.73       286\n",
      "weighted avg       0.73      0.73      0.73       286\n",
      "\n",
      "Decision Tree with 0.2 testing split\n",
      "Training time:  0.02200484275817871\n",
      "Accuracy:  0.8636363636363636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       142\n",
      "           1       0.83      0.91      0.87       144\n",
      "\n",
      "    accuracy                           0.86       286\n",
      "   macro avg       0.87      0.86      0.86       286\n",
      "weighted avg       0.87      0.86      0.86       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change testing split to 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 100545358)\n",
    "\n",
    "# Re-encode the target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"Logistic Regression with 0.2 testing split\")\n",
    "# Define the model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', LogisticRegression(random_state=100545358))])\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train_encoded)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: \", end - start)\n",
    "\n",
    "# Predict the target values\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n",
    "print(\"KNN with 0.2 testing split\")\n",
    "# Define the model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train_encoded)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: \", end - start)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n",
    "print(\"Decision Tree with 0.2 testing split\")\n",
    "\n",
    "# Define the model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', DecisionTreeClassifier(random_state=100545358))])\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train_encoded)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: \", end - start)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Chosen Method is: __________?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: Compare with the Dummy Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Accuracy:  0.4965034965034965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.66       142\n",
      "           1       0.00      0.00      0.00       144\n",
      "\n",
      "    accuracy                           0.50       286\n",
      "   macro avg       0.25      0.50      0.33       286\n",
      "weighted avg       0.25      0.50      0.33       286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\derek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\derek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\derek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# using DummyClassifier as a baseline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state = 100545358)\n",
    "dummy.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred = dummy.predict(X_test)\n",
    "\n",
    "dummy_accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Dummy Classifier Accuracy: \", dummy_accuracy)\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n",
    "# the dummy classifier has an accuracy of 0.5, and precision/recall/f1-score of 0 in the 1 class\n",
    "# the 1 class is the class that has left the company, so the dummy classifier is predicting that no one has left the company\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of Methods: Confusion Matrix \n",
    "\n",
    "We can check how many False Positives and False Negatives are being predicted by our model, to see how it is performing overall\n",
    "\n",
    "We want to minimize both of these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
