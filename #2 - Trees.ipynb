{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTDjHDbUwnvN"
      },
      "source": [
        "![LogoUC3M](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Acr%C3%B3nimo_y_nombre_de_la_UC3M.svg/320px-Acr%C3%B3nimo_y_nombre_de_la_UC3M.svg.png)\n",
        "\n",
        "### Machine Learning Â· Bachelor in Management and Technology\n",
        "# Tutorial 1: Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2rNJKxq1fTI",
        "outputId": "c988af46-a0a6-47dc-f85f-402906871d06"
      },
      "outputs": [],
      "source": [
        "# This is for installing model trees, that will be used at the end\n",
        "!pip install --upgrade linear-tree\n",
        "\n",
        "# More info about this implementation of model trees\n",
        "# https://towardsdatascience.com/linear-tree-the-perfect-mix-of-linear-model-and-decision-tree-2eaed21936b7\n",
        "# https://pypi.org/project/linear-tree/\n",
        "\n",
        "# Install statsmodels for confidence intervals\n",
        "!pip install statsmodels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1HKbQlo4QXs"
      },
      "source": [
        "# Training a decision tree for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHqnB5gFbLOv",
        "outputId": "cab758c9-6460-4137-a64c-bc770a65523f"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Features and target variable\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Feature names and target names\n",
        "feature_names = iris.feature_names\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Display the shape of features and target\n",
        "print(\"Shape of X (features):\", X.shape)\n",
        "print(\"Shape of y (target):\", y.shape)\n",
        "print(\"Feature names:\", feature_names)\n",
        "print(\"Target names:\", target_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "9zidraxu4QXt",
        "outputId": "b6f3318b-4bb1-42a2-dba1-cc1c0058bff5"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "# Here, we define the type of training method (nothing happens yet)\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "# Now, we train (fit) the method on the (X,y) dataset\n",
        "clf.fit(X, y)\n",
        "# clf **has been changed** and now contains the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgtYgDGH4QXt"
      },
      "source": [
        "We can visualize the tree as text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXdfMAUC4QXt",
        "outputId": "72165489-fc22-465f-b34f-37749f3047dc"
      },
      "outputs": [],
      "source": [
        "text_representation = tree.export_text(clf, feature_names=feature_names)\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvjUKYTd4QXt"
      },
      "source": [
        "We can also visualize the tree graphically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "LPEoeoGc4QXu",
        "outputId": "3f002a39-1919-4ca5-a88d-90c481444b32"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(25,20))\n",
        "_ = tree.plot_tree(clf,\n",
        "                   feature_names = feature_names,\n",
        "                   class_names= target_names,\n",
        "                   filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDexRXHP4QXu"
      },
      "source": [
        "# Training and evaluating a decision tree with a test set (holdout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7uNOyNv4QXu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-4APKeP4QXu"
      },
      "source": [
        "- Now we create the training (X_train, y_train) and testing (X_test, y_test) partitions: 2/3 for training, 1/3 for testing\n",
        "- Notice the **random_state=42** for reproducibility (important!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSfsVFxH4QXu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1OxaH3-4QXv"
      },
      "source": [
        "Shape of the training and testing partitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLayO_Ir4QXv",
        "outputId": "3e075d9c-799d-4642-a6ed-e3b892360953"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, y_train.shape) # 100 instances for training\n",
        "print(X_test.shape, y_test.shape)   # 50 instances for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxjyn5es4QXv"
      },
      "source": [
        "Let's print the five first training instances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W36mNPh4QXw"
      },
      "source": [
        "- Now, we train the tree with .fit\n",
        "- Notice that we use random_state=42 so that the training of the tree is also reproducible (in case that tree training is not deterministic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGUABN5a4QXw",
        "outputId": "1230ee81-23f4-4f38-f050-0fdb6804837c"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "\n",
        "# Here, we set our model to classification tree\n",
        "clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "# Now, we train it\n",
        "clf.fit(X_train, y_train)\n",
        "# We can see that the tree is inside\n",
        "print(tree.export_text(clf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jqPY0dT4QXw"
      },
      "source": [
        "Now, we evaluate the tree, by computing predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCGTo5oO4QXx"
      },
      "outputs": [],
      "source": [
        "y_test_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCpZW27s4QXx"
      },
      "source": [
        "- But, in order to evaluate the model on the test partition, we can compute a metric (classification accuracy in this case)\n",
        "- It is very high (98%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uspUaRJe4QXx",
        "outputId": "9d31ba94-f923-4c79-a3ab-4d013cd34c61"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
        "print(accuracy_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjgSbJvq4QXx"
      },
      "source": [
        "However, the 0.98 accuracy is the model evaluation (estimation of performance). We still need to compute the final model (the one that will be sent and used by the company) **using all available data**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "VN0n0ZU94QXy",
        "outputId": "5406821d-0105-4cc0-8d4e-a105b7cc939a"
      },
      "outputs": [],
      "source": [
        "final_clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "# Making results reproducible, in case training a tree contains random decisions\n",
        "\n",
        "# Now, we train it\n",
        "final_clf.fit(X, y)\n",
        "# final_clf contains the model that would be used by the company\n",
        "# Its estimated accuracy is what we computed before (95%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObJu3av94QXy"
      },
      "source": [
        "Below, you have the complete code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "Fv2Zgzb94QXy",
        "outputId": "2c1bdd66-8056-4d5f-a8f0-6d87a5ffda56"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Here, we set our model to classification tree\n",
        "clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "# We train it\n",
        "clf.fit(X_train, y_train)\n",
        "# We obtain predictions on the test set\n",
        "y_test_pred = clf.predict(X_test)\n",
        "# We compute accuracy\n",
        "accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Accuracy of the tree: {accuracy_tree} \")\n",
        "\n",
        "# We finally compute the final model with all available data\n",
        "\n",
        "final_clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "final_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX9_a4E94QXy"
      },
      "source": [
        "# Training and evaluating a decision tree with crossvalidation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r121gQdC4QX0"
      },
      "source": [
        "- KFold creates the training/test crossvalidation folds.\n",
        "    - shuffle randomly shuffles the data before splitting the folds. We should always do this, unless we have good reasons otherwise\n",
        "    - random_state makes the shuffling reproducible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECsSw2by4QX0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejuZVow54QX1",
        "outputId": "694c557f-5a6e-47d1-d166-e9ee45084311"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# create a k-fold crossvalidation iterator of k=5 folds\n",
        "# shuffle = True randomly rearranges the dataframe\n",
        "# random_state = 42 is for making the folds reproducible\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, scoring='accuracy', cv = cv)\n",
        "\n",
        "print(f\"All the accuracies are: {scores}\")\n",
        "print(f\"And the average crossvalidation accuracy is: {scores.mean():.2f} +- {scores.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INNQMn8n4QX1"
      },
      "source": [
        "- 0.95 is the model evaluation (estimation of performance).\n",
        "- But the final model has to be trained with all available data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "yNXty5034QX1",
        "outputId": "c205de38-d60b-4186-f38c-4ca4c75144bc"
      },
      "outputs": [],
      "source": [
        "final_clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "# Now, we train it\n",
        "final_clf.fit(X, y)\n",
        "# final_clf contains the model that would be used by the company\n",
        "# Its estimated accuracy is what we computed before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prQCnIMt4QX1"
      },
      "source": [
        "Below, you have the complete code for crossvalidation evaluation (and also obtaining the final model at the end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "ZT8P6pJz4QX1",
        "outputId": "85a949fb-3f1b-4f60-f48c-1a76098a64f8"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "# create a k-fold crossvalidation iterator of k=5 folds\n",
        "# shuffle = True randomly rearranges the dataframe\n",
        "# random_state = 42 is for making the folds reproducible\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, scoring='accuracy', cv = cv)\n",
        "\n",
        "# print(f\"All the accuracies are: {scores}\")\n",
        "print(f\"The average crossvalidation accuracy is: {scores.mean():.2f} +- {scores.std():.2f}\")\n",
        "\n",
        "final_clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "# Now, we train it\n",
        "final_clf.fit(X, y)\n",
        "# final_clf contains the model that would be used by the company"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7FP2q4V4QX1"
      },
      "source": [
        "# Changing hyperparameters of a decision tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewZT0QkW4QX1"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q_jHJgb4QX1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0eoV0e54QX2"
      },
      "source": [
        "Let's see the effect of changing from gini to entropy. We use holdout here. It seems that results are exactly the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN-4gAJg4QX2",
        "outputId": "3dd86f30-736a-4b23-f04a-59959ea23d6e"
      },
      "outputs": [],
      "source": [
        "# This loop checks what happens with the two criterions\n",
        "for criterion in [\"gini\", \"entropy\"]:\n",
        "    clf = tree.DecisionTreeClassifier(criterion=criterion, random_state=42)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
        "    print(f\"With {criterion}: {accuracy_tree:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgKDmuV84QX2"
      },
      "source": [
        "Let's see the effects of maximum_depth. \"None\" represents the maximum possible depth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHjavMZk4QX2",
        "outputId": "5f9d6fb6-5755-462b-ff49-18de9b779cc8"
      },
      "outputs": [],
      "source": [
        "for max_depth in [1,2,3,None]:\n",
        "    clf = tree.DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
        "    print(f\"With max_depth {max_depth}: {accuracy_tree:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ1FfR1l4QX2"
      },
      "source": [
        "It seems that max_depth=2 is enough. Let's visualize a tree with max depth = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "2ipRiYjF4QX2",
        "outputId": "de3c7a82-c107-409c-f351-a43e44344f73"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5,4))\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "_ = tree.plot_tree(clf,\n",
        "                   feature_names = feature_names,\n",
        "                   class_names= target_names,\n",
        "                   filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Vh6got4QX2"
      },
      "source": [
        "Let's see the effects of min_samples_split. 2 is the default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1BeviS94QX2",
        "outputId": "f4f2b95c-81c1-40cb-ef54-b0484a7a078e"
      },
      "outputs": [],
      "source": [
        "for min_samples in [2,10,20,30,100]:\n",
        "    clf = tree.DecisionTreeClassifier(min_samples_split=min_samples, random_state=42)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
        "    print(f\"With min_samples_split {min_samples}: {accuracy_tree:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkXAUuStFKid"
      },
      "source": [
        "Finally, let's check another hyper-parameter called min_impurity_decrease: this means that a new level of the tree is created only if the information gain (that is, the decrease in entropy or gini) is larger than min_impurity_decrease. It is yet another way of controlling tree depth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su3NPiA94QX3",
        "outputId": "32586210-ba62-4f42-8ebb-7a8f080d5f92"
      },
      "outputs": [],
      "source": [
        "for min_impurity_decrease in np.linspace(0,2,num=10):\n",
        "    clf = tree.DecisionTreeClassifier(min_impurity_decrease=min_impurity_decrease,\n",
        "                                      random_state=42)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
        "    print(f\"With min_impurity_decrease {min_impurity_decrease}: {accuracy_tree:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGwW0YWM4QX3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "tennis_df = pd.read_csv(\"https://raw.githubusercontent.com/emiliomartin84/Machine_Learning_Uc3m/main/Data/tennis.txt\", sep=\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mdqmMcdKYcl"
      },
      "source": [
        "**With** this dataset is very small, so we can visualize it whole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pGckFPDlKdc2",
        "outputId": "94d1da49-b708-4658-d112-813c917c46bc"
      },
      "outputs": [],
      "source": [
        "tennis_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nNMSi19hfKP"
      },
      "source": [
        "# **Exercise (long):** Go back to the KNN tutorial and use a ColumnTransformer to fit a tree on the training set. Then use the trained model for making predictions on the testing set, and finally compute the testing accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADfIN64L4QX4"
      },
      "source": [
        "# Regression trees with holdout evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2r3ejoO4QX4"
      },
      "source": [
        "Let's load the California Housing dataset and check its description. Its data about housing prices depending on the characteristics of the zone**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRUioZm04QX4",
        "outputId": "da5125a6-de79-41de-9dd3-be14c7ef16b0"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Fetch the California Housing dataset\n",
        "california_housing = fetch_california_housing()\n",
        "\n",
        "# Features and target variable\n",
        "X = california_housing.data\n",
        "y = california_housing.target\n",
        "\n",
        "# Feature names\n",
        "feature_names = california_housing.feature_names\n",
        "\n",
        "# Display the shape of features and target\n",
        "print(\"Shape of X (features):\", X.shape)\n",
        "print(\"Shape of y (target):\", y.shape)\n",
        "print(\"Feature names:\", feature_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APMXvjj14QX4"
      },
      "source": [
        "The main change is that we use a DecisionTreeRegressor and the metric is now RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ21Wukc4QX5",
        "outputId": "f32b653d-fbe8-46c3-bf0e-e74c72d49416"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "import numpy as np\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Here, we set our model to classification tree\n",
        "regr = tree.DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# We train it\n",
        "regr.fit(X_train, y_train)\n",
        "# We obtain predictions on the test set\n",
        "y_test_pred = regr.predict(X_test)\n",
        "# We compute accuracy\n",
        "rmse_tree = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
        "print(f\"RMSE of the tree: {rmse_tree}\")\n",
        "\n",
        "# We would have to compute the final model with all available data (X,y)\n",
        "# Not done here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZnnKRiQyNOH"
      },
      "source": [
        "Is it better than a trivial regressor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQiGRsbpyN0z",
        "outputId": "d87a738c-b921-4d9a-bb60-5d7f6fd2c61a"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "regr_mean = DummyRegressor(strategy=\"mean\")\n",
        "regr_mean.fit(X_train, y_train)\n",
        "rmse_mean = np.sqrt(metrics.mean_squared_error(y_test, regr_mean.predict(X_test)))\n",
        "\n",
        "print(f\"RMSE of the tree: {rmse_tree}\")\n",
        "print(f\"RMSE of dummy(mean): {rmse_mean}\")\n",
        "print(f\"RMSE ratio tree/dummy(mean): {rmse_tree/rmse_mean}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ0bJSuz4QX5"
      },
      "source": [
        "The tree has more than 10 levels and it is very hard to visualize. Let's visualize one with only two levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "V1-moMyM4QX5",
        "outputId": "0262e921-845d-489a-cd71-480b63dfd087"
      },
      "outputs": [],
      "source": [
        "regr = tree.DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "\n",
        "# We train it\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(25,20))\n",
        "\n",
        "_ = tree.plot_tree(regr,\n",
        "                   feature_names = feature_names,\n",
        "                   filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6in65Vuu4QX5"
      },
      "source": [
        "**Now we train model trees (for regression)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBI37quR4QX5"
      },
      "outputs": [],
      "source": [
        "# More info about this implementation of model trees\n",
        "# https://towardsdatascience.com/linear-tree-the-perfect-mix-of-linear-model-and-decision-tree-2eaed21936b7\n",
        "# https://pypi.org/project/linear-tree/\n",
        "\n",
        "# IMPORTANT: This implementation of Model Trees is able to deal with Categorical Features (whose values are encoded as integers 0,1,2, ...)\n",
        "# in order to use categorical features, the parameter categorical_features must be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMTJR8N61dsr"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade linear-tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rHXrM9B4QX5",
        "outputId": "3891c6d9-eea3-4420-a484-65a77ce821a9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from lineartree import LinearTreeRegressor\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "regr = LinearTreeRegressor(base_estimator=LinearRegression())\n",
        "\n",
        "# We train it\n",
        "regr.fit(X_train, y_train)\n",
        "# We obtain predictions on the test set\n",
        "y_test_pred = regr.predict(X_test)\n",
        "# We compute accuracy\n",
        "rmse_tree = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
        "print(f\"RMSE of the tree: {rmse_tree}\")\n",
        "\n",
        "# We would have to compute the final model with all available data\n",
        "# Not done here, only interested on test RMSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZMaKH1q86_U"
      },
      "source": [
        "The internal nodes of the model tree below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "xmXWQ1SD4QX5",
        "outputId": "35845cf0-95bf-48af-9fb4-e3bc88b2a6fc"
      },
      "outputs": [],
      "source": [
        "regr.plot_model(feature_names=feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeGJtMBM9Djz"
      },
      "source": [
        "In order to check the linear models at the leaves, we have to follow a longer process. What follows shows the coefficient of the linear model at node 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgM4K5gS4Ac4"
      },
      "outputs": [],
      "source": [
        "leaves = regr.summary(feature_names=feature_names, only_leaves=True, max_depth=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ika31dVu4xgB",
        "outputId": "61c5f739-bd7e-4e92-bc0d-39e9a837cbf7"
      },
      "outputs": [],
      "source": [
        "leaves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jpFdkSA6C-H",
        "outputId": "4ed15dd6-462d-4345-92e5-a7281be39db1"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "model_7_coefs = leaves[7]['models'].coef_\n",
        "model_7_intercept = leaves[7]['models'].intercept_\n",
        "pprint(list(zip(feature_names, model_7_coefs)))\n",
        "pprint(f'intercept: {model_7_intercept}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4As4OQmq8FFE"
      },
      "outputs": [],
      "source": [
        "?LinearTreeRegressor"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
